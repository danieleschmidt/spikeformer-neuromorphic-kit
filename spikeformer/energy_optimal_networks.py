"""Energy-Optimal Spike Timing Networks - Revolutionary breakthrough for brain-like efficiency."""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
from typing import List, Dict, Tuple, Optional, Any, Callable
from dataclasses import dataclass, field
from collections import defaultdict, deque
from abc import ABC, abstractmethod
from enum import Enum
import logging

from .neurons import create_neuron, LifNeuron
from .encoding import create_encoder
from .models import SpikingConfig


class EnergyOptimizationObjective(Enum):
    """Energy optimization objectives for spike timing."""
    MINIMIZE_TOTAL_ENERGY = "minimize_total"
    MAXIMIZE_ENERGY_EFFICIENCY = "maximize_efficiency"
    MINIMIZE_ENERGY_PER_BIT = "minimize_per_bit"
    BALANCE_ACCURACY_ENERGY = "balance_accuracy_energy"


class SpikeTimingStrategy(Enum):
    """Strategies for optimal spike timing."""
    INFORMATION_THEORETICAL = "information_theoretical"
    METABOLIC_COST_BASED = "metabolic_cost"
    SPARSE_CODING = "sparse_coding"
    PREDICTIVE_CODING = "predictive_coding"
    ADAPTIVE_THRESHOLD = "adaptive_threshold"


@dataclass
class EnergyOptimalConfig:
    """Configuration for energy-optimal spike timing networks."""
    # Energy parameters (based on biological measurements)
    spike_energy_cost: float = 1e-12  # Joules per spike
    baseline_metabolic_rate: float = 1e-15  # Joules per second per neuron
    synaptic_transmission_cost: float = 1e-14  # Joules per synaptic event
    refractory_period_cost: float = 5e-16  # Additional cost during refractory period
    
    # Information theoretical parameters
    target_information_rate: float = 10.0  # bits per second
    redundancy_penalty: float = 0.1
    mutual_information_threshold: float = 0.5
    entropy_regularization: float = 0.01
    
    # Optimization parameters
    energy_budget: float = 1e-6  # Total energy budget in Joules
    efficiency_target: float = 1e6  # bits per Joule
    optimization_window: int = 1000  # timesteps for optimization
    learning_rate_energy: float = 0.001
    
    # Adaptive parameters
    threshold_adaptation_rate: float = 0.01
    firing_rate_target: float = 0.05  # Target firing rate (5% sparsity)
    homeostatic_time_constant: float = 10000.0
    predictive_horizon: int = 20  # timesteps for prediction
    
    # Network architecture
    lateral_inhibition_strength: float = 0.3
    winner_take_all_strength: float = 0.5
    temporal_competition_window: int = 5


class EnergyAwareNeuron:
    """Energy-aware neuron with optimal spike timing."""
    
    def __init__(self, neuron_id: int, config: EnergyOptimalConfig):
        self.neuron_id = neuron_id
        self.config = config
        
        # Basic neuron dynamics
        self.membrane_potential = 0.0
        self.threshold = 1.0
        self.refractory_counter = 0.0
        self.refractory_period = 2.0
        
        # Energy tracking
        self.energy_consumed = 0.0
        self.energy_per_spike = config.spike_energy_cost
        self.baseline_energy_rate = config.baseline_metabolic_rate
        
        # Information metrics
        self.information_transmitted = 0.0
        self.bits_per_spike = 0.0
        self.mutual_information_history = deque(maxlen=1000)
        
        # Spike timing optimization
        self.spike_times = deque(maxlen=1000)
        self.optimal_spike_times = []
        self.timing_errors = deque(maxlen=100)
        
        # Predictive coding
        self.prediction_error = 0.0
        self.predicted_input = 0.0
        self.prediction_accuracy = 0.5
        
        # Adaptive threshold
        self.adaptive_threshold = self.threshold
        self.firing_rate_estimate = 0.0
        self.threshold_trace = 0.0
        
        # Metabolic state
        self.metabolic_demand = 1.0
        self.energy_efficiency = 0.0  # bits per Joule
        self.last_efficiency_update = 0
        
        # Sparse coding components
        self.sparse_code = torch.zeros(64)  # Sparse representation
        self.dictionary_elements = torch.randn(64, 32) * 0.1  # Dictionary for sparse coding
        self.sparsity_level = 0.05
        
    def compute_optimal_spike_timing(self, inputs: torch.Tensor, 
                                   current_time: int) -> Tuple[bool, float]:
        """Compute optimal spike timing based on energy-information trade-off."""
        
        # Update predictions
        self._update_predictions(inputs, current_time)
        
        # Calculate information content of potential spike
        spike_information = self._calculate_spike_information(inputs, current_time)
        
        # Calculate energy cost of spiking now vs. later
        immediate_energy_cost = self._calculate_immediate_energy_cost()
        delayed_energy_cost = self._calculate_delayed_energy_cost(inputs)
        
        # Information-theoretic optimal timing
        optimal_timing = self._compute_information_optimal_timing(
            spike_information, immediate_energy_cost, delayed_energy_cost
        )
        
        # Apply metabolic constraints
        metabolic_feasible = self._check_metabolic_feasibility(immediate_energy_cost)
        
        # Make spike decision
        should_spike = (optimal_timing < 1.0) and metabolic_feasible and (self.refractory_counter <= 0)
        
        if should_spike:
            spike_timing_score = optimal_timing
        else:
            spike_timing_score = float('inf')  # Not optimal to spike now
            
        return should_spike, spike_timing_score
    
    def _update_predictions(self, inputs: torch.Tensor, current_time: int):
        """Update predictive model for future inputs."""
        if len(self.spike_times) < 2:
            return
            
        # Simple linear prediction based on recent history
        recent_inputs = inputs[-min(10, len(inputs)):]  # Last 10 timesteps
        
        if len(recent_inputs) > 1:
            # Linear extrapolation
            slope = torch.mean(recent_inputs[1:] - recent_inputs[:-1])
            self.predicted_input = recent_inputs[-1] + slope
        else:
            self.predicted_input = recent_inputs[-1] if len(recent_inputs) > 0 else 0.0
        
        # Calculate prediction error
        if current_time > 0:
            actual_input = inputs[-1] if len(inputs) > 0 else 0.0
            self.prediction_error = abs(actual_input - self.predicted_input)
            
            # Update prediction accuracy
            self.prediction_accuracy = 0.9 * self.prediction_accuracy + 0.1 * (1.0 - self.prediction_error)
    
    def _calculate_spike_information(self, inputs: torch.Tensor, current_time: int) -> float:
        """Calculate information content of a potential spike."""
        
        # Method 1: Surprise-based information (negative log probability)
        spike_probability = torch.sigmoid(inputs[-1] - self.adaptive_threshold)
        surprise_information = -torch.log(spike_probability + 1e-8).item()
        
        # Method 2: Mutual information with recent history
        mutual_info = self._calculate_mutual_information(inputs)
        
        # Method 3: Predictive coding information
        prediction_error_info = abs(self.prediction_error) / (abs(self.predicted_input) + 1e-6)
        
        # Method 4: Sparse coding information
        sparse_info = self._calculate_sparse_coding_information(inputs)
        
        # Combine information measures
        total_information = (
            0.4 * surprise_information + 
            0.3 * mutual_info + 
            0.2 * prediction_error_info +
            0.1 * sparse_info
        )
        
        return max(0.0, total_information)
    
    def _calculate_mutual_information(self, inputs: torch.Tensor) -> float:
        """Calculate mutual information between spike and recent inputs."""
        if len(inputs) < 10:
            return 0.0
        
        recent_inputs = inputs[-10:].numpy()
        
        # Discretize inputs for MI calculation
        input_bins = np.digitize(recent_inputs, bins=np.linspace(-3, 3, 10))
        
        # Calculate joint and marginal probabilities
        joint_counts = np.zeros((2, 10))  # [no_spike, spike] x [input_bins]
        
        for i, inp_bin in enumerate(input_bins):
            # Assume binary spike pattern for simplicity
            spike = 1 if recent_inputs[i] > self.adaptive_threshold else 0
            if inp_bin < 10:
                joint_counts[spike, inp_bin-1] += 1
        
        # Add smoothing
        joint_counts += 1e-6
        joint_probs = joint_counts / joint_counts.sum()
        
        # Marginal probabilities
        spike_probs = joint_probs.sum(axis=1)
        input_probs = joint_probs.sum(axis=0)
        
        # Mutual information
        mi = 0.0
        for s in range(2):
            for i in range(10):
                if joint_probs[s, i] > 1e-10:
                    mi += joint_probs[s, i] * np.log(
                        joint_probs[s, i] / (spike_probs[s] * input_probs[i] + 1e-10)
                    )
        
        return max(0.0, mi)
    
    def _calculate_sparse_coding_information(self, inputs: torch.Tensor) -> float:
        """Calculate information based on sparse coding principles."""
        if len(inputs) == 0:
            return 0.0
            
        current_input = inputs[-1]
        
        # Project input onto sparse dictionary
        projections = torch.matmul(self.dictionary_elements, current_input.unsqueeze(0).T).squeeze()
        
        # Soft thresholding for sparsity
        threshold = torch.quantile(torch.abs(projections), 1.0 - self.sparsity_level)
        sparse_projections = torch.sign(projections) * torch.clamp(
            torch.abs(projections) - threshold, min=0.0
        )
        
        # Information is related to the number of active dictionary elements
        active_elements = torch.sum(torch.abs(sparse_projections) > 1e-6)
        
        # Information content based on sparsity and activation strength
        sparsity_info = active_elements.float() * torch.mean(torch.abs(sparse_projections))
        
        return sparsity_info.item()
    
    def _calculate_immediate_energy_cost(self) -> float:
        """Calculate energy cost of spiking immediately."""
        base_cost = self.energy_per_spike
        
        # Additional costs during refractory period
        if self.refractory_counter > 0:
            refractory_penalty = self.config.refractory_period_cost * self.refractory_counter
            base_cost += refractory_penalty
        
        # Metabolic state modulation
        metabolic_multiplier = self.metabolic_demand
        
        return base_cost * metabolic_multiplier
    
    def _calculate_delayed_energy_cost(self, inputs: torch.Tensor) -> float:
        """Calculate expected energy cost of delaying the spike."""
        
        # If we don't spike now, we still pay baseline metabolic cost
        baseline_cost = self.baseline_energy_rate
        
        # Additional cost if we need to spike later with potentially higher threshold
        future_spike_probability = 0.7  # Assume 70% chance we'll need to spike later
        future_threshold_increase = 0.1  # Threshold may increase due to homeostasis
        
        delayed_spike_cost = future_spike_probability * (
            self.energy_per_spike * (1.0 + future_threshold_increase)
        )
        
        # Cost of maintaining membrane potential
        maintenance_cost = 0.1 * self.baseline_energy_rate * abs(self.membrane_potential)
        
        return baseline_cost + delayed_spike_cost + maintenance_cost
    
    def _compute_information_optimal_timing(self, information: float, 
                                          immediate_cost: float, 
                                          delayed_cost: float) -> float:
        """Compute optimal timing based on information-energy trade-off."""
        
        # Information rate if we spike now
        immediate_info_rate = information  # bits
        immediate_energy_rate = immediate_cost  # Joules
        
        # Information rate if we delay
        delayed_info_rate = information * 0.8  # Information may decay
        delayed_energy_rate = delayed_cost
        
        # Energy efficiency scores
        if immediate_energy_rate > 0:
            immediate_efficiency = immediate_info_rate / immediate_energy_rate
        else:
            immediate_efficiency = float('inf')
            
        if delayed_energy_rate > 0:
            delayed_efficiency = delayed_info_rate / delayed_energy_rate
        else:
            delayed_efficiency = float('inf')
        
        # Optimal timing score (lower is better)
        if immediate_efficiency >= delayed_efficiency:
            timing_score = 0.5  # Good time to spike
        else:
            timing_score = 1.5  # Better to wait
            
        # Apply information urgency
        if information > 2.0:  # High information content
            timing_score *= 0.8  # More urgent to spike
        elif information < 0.5:  # Low information content
            timing_score *= 1.5  # Less urgent to spike
        
        return timing_score
    
    def _check_metabolic_feasibility(self, energy_cost: float) -> bool:
        """Check if spike is metabolically feasible given energy budget."""
        
        # Simple energy budget check
        if self.energy_consumed + energy_cost > self.config.energy_budget:
            return False
        
        # Rate limiting based on metabolic demand
        if hasattr(self, 'last_spike_time'):
            time_since_last_spike = len(self.spike_times) - self.last_spike_time
            min_isi = 1.0 / (self.config.firing_rate_target * 50)  # Minimum ISI
            
            if time_since_last_spike < min_isi:
                return False
        
        return True
    
    def execute_spike(self, current_time: int, information_content: float):
        """Execute spike and update energy/information tracking."""
        
        # Record spike
        self.spike_times.append(current_time)
        self.last_spike_time = current_time
        
        # Update energy consumption
        spike_cost = self._calculate_immediate_energy_cost()
        self.energy_consumed += spike_cost
        
        # Update information transmission
        self.information_transmitted += information_content
        self.bits_per_spike = information_content
        
        # Update energy efficiency
        if spike_cost > 0:
            self.energy_efficiency = information_content / spike_cost
        
        # Reset membrane potential and start refractory period
        self.membrane_potential = 0.0
        self.refractory_counter = self.refractory_period
        
        # Update adaptive threshold based on homeostatic mechanisms
        self._update_adaptive_threshold()
    
    def _update_adaptive_threshold(self):
        """Update adaptive threshold for homeostatic control."""
        
        # Calculate recent firing rate
        if len(self.spike_times) >= 10:
            recent_spikes = list(self.spike_times)[-10:]
            time_window = recent_spikes[-1] - recent_spikes[0] + 1
            current_rate = len(recent_spikes) / time_window
        else:
            current_rate = 0.0
        
        self.firing_rate_estimate = (
            0.9 * self.firing_rate_estimate + 0.1 * current_rate
        )
        
        # Homeostatic threshold adjustment
        rate_error = self.firing_rate_estimate - self.config.firing_rate_target
        
        threshold_adjustment = (
            self.config.threshold_adaptation_rate * rate_error
        )
        
        self.adaptive_threshold = max(0.1, self.threshold + threshold_adjustment)
        
        # Update metabolic demand based on activity
        if self.firing_rate_estimate > self.config.firing_rate_target * 1.5:
            self.metabolic_demand *= 1.01  # Increase metabolic cost for overactive neurons
        elif self.firing_rate_estimate < self.config.firing_rate_target * 0.5:
            self.metabolic_demand *= 0.99  # Decrease metabolic cost for underactive neurons
        
        self.metabolic_demand = np.clip(self.metabolic_demand, 0.5, 2.0)
    
    def update_between_spikes(self, dt: float = 1.0):
        """Update neuron state between spikes."""
        
        # Decay refractory counter
        if self.refractory_counter > 0:
            self.refractory_counter = max(0, self.refractory_counter - dt)
        
        # Baseline metabolic cost
        self.energy_consumed += self.baseline_energy_rate * dt
        
        # Update threshold trace for adaptation
        self.threshold_trace *= np.exp(-dt / self.config.homeostatic_time_constant)


class EnergyOptimalNetwork(nn.Module):
    """Network optimized for energy-efficient spike timing."""
    
    def __init__(self, input_size: int, hidden_sizes: List[int], output_size: int,
                 config: EnergyOptimalConfig):
        super().__init__()
        self.config = config
        self.input_size = input_size
        self.output_size = output_size
        self.hidden_sizes = hidden_sizes
        
        # Create energy-aware neurons
        self.neurons = {}
        self.layer_sizes = [input_size] + hidden_sizes + [output_size]
        neuron_id = 0
        
        for layer_idx, layer_size in enumerate(self.layer_sizes):
            for _ in range(layer_size):
                self.neurons[neuron_id] = EnergyAwareNeuron(neuron_id, config)
                neuron_id += 1
        
        # Create optimized connections
        self.connections = self._create_energy_optimal_connections()
        
        # Global optimization components
        self.global_energy_monitor = GlobalEnergyMonitor(config)
        self.spike_timing_optimizer = SpikeTimingOptimizer(config)
        self.information_maximizer = InformationMaximizer(config)
        
        # Network-level energy metrics
        self.total_energy_consumed = 0.0
        self.total_information_transmitted = 0.0
        self.network_efficiency = 0.0
        
    def _create_energy_optimal_connections(self) -> Dict[Tuple[int, int], float]:
        """Create connections optimized for energy efficiency."""
        connections = {}
        
        layer_boundaries = [0]
        for size in self.layer_sizes:
            layer_boundaries.append(layer_boundaries[-1] + size)
        
        # Connect adjacent layers with energy-optimal topology
        for layer_idx in range(len(self.layer_sizes) - 1):
            pre_start = layer_boundaries[layer_idx]
            pre_end = layer_boundaries[layer_idx + 1]
            post_start = layer_boundaries[layer_idx + 1]
            post_end = layer_boundaries[layer_idx + 2]
            
            for pre_id in range(pre_start, pre_end):
                for post_id in range(post_start, post_end):
                    # Energy-optimal connectivity probability
                    distance = abs(pre_id - post_id)
                    connectivity_prob = np.exp(-distance / 10.0) * 0.3
                    
                    if np.random.random() < connectivity_prob:
                        # Weight optimized for energy efficiency
                        weight = self._compute_energy_optimal_weight(pre_id, post_id)
                        connections[(pre_id, post_id)] = weight
        
        return connections
    
    def _compute_energy_optimal_weight(self, pre_id: int, post_id: int) -> float:
        """Compute energy-optimal synaptic weight."""
        
        # Base weight
        base_weight = np.random.normal(0.0, 0.1)
        
        # Energy cost of strong connections
        energy_penalty = 0.1 * abs(base_weight)
        
        # Information benefit of strong connections
        info_benefit = 0.2 * abs(base_weight)
        
        # Optimize for energy-information trade-off
        optimal_weight = base_weight * (info_benefit / (energy_penalty + 1e-6))
        
        return np.clip(optimal_weight, -1.0, 1.0)
    
    def forward(self, x: torch.Tensor, timesteps: int = 50) -> Tuple[torch.Tensor, Dict[str, float]]:
        """Forward pass with energy-optimal spike timing."""
        
        batch_size = x.size(0)
        
        # Initialize spike patterns
        spike_patterns = {neuron_id: [] for neuron_id in self.neurons.keys()}
        
        # Encode input to initial spike pattern
        input_spikes = self._encode_input_to_spikes(x, timesteps)
        
        # Simulate network dynamics with optimal timing
        for t in range(timesteps):
            current_spikes = {}
            
            # Input layer spikes
            for neuron_id in range(self.input_size):
                if neuron_id in input_spikes and t < len(input_spikes[neuron_id]):
                    current_spikes[neuron_id] = input_spikes[neuron_id][t]
                    if current_spikes[neuron_id]:
                        spike_patterns[neuron_id].append(t)
            
            # Process hidden and output layers
            for neuron_id in range(self.input_size, len(self.neurons)):
                neuron = self.neurons[neuron_id]
                
                # Collect synaptic inputs
                synaptic_input = 0.0
                for (pre_id, post_id), weight in self.connections.items():
                    if post_id == neuron_id and pre_id in current_spikes and current_spikes[pre_id]:
                        synaptic_input += weight
                
                # Update membrane potential
                neuron.membrane_potential += synaptic_input - 0.1 * neuron.membrane_potential
                
                # Optimal spike timing decision
                should_spike, timing_score = neuron.compute_optimal_spike_timing(
                    torch.tensor([synaptic_input]), t
                )
                
                if should_spike:
                    # Execute spike with energy and information tracking
                    information_content = neuron._calculate_spike_information(
                        torch.tensor([synaptic_input]), t
                    )
                    neuron.execute_spike(t, information_content)
                    current_spikes[neuron_id] = True
                    spike_patterns[neuron_id].append(t)
                else:
                    current_spikes[neuron_id] = False
                
                # Update neuron state between spikes
                neuron.update_between_spikes()
        
        # Convert spike patterns to output
        output = self._decode_spikes_to_output(spike_patterns, batch_size, timesteps)
        
        # Calculate network-level metrics
        network_metrics = self._calculate_network_metrics()
        
        return output, network_metrics
    
    def _encode_input_to_spikes(self, x: torch.Tensor, timesteps: int) -> Dict[int, List[bool]]:
        """Encode input to energy-optimal spike patterns."""
        input_spikes = {}
        
        for neuron_id in range(self.input_size):
            spikes = []
            input_value = x[0, neuron_id].item()  # Assume batch_size = 1
            
            # Poisson-like encoding optimized for energy efficiency
            mean_rate = torch.sigmoid(torch.tensor(input_value)).item()
            
            # Optimal spike placement to minimize energy while preserving information
            for t in range(timesteps):
                # Energy-optimal probability
                base_prob = mean_rate / timesteps
                
                # Information-theoretic adjustment
                if t == 0:
                    info_boost = 1.5  # First spike carries more information
                elif t < timesteps // 2:
                    info_boost = 1.2  # Early spikes are more efficient
                else:
                    info_boost = 0.8  # Later spikes are less efficient
                
                spike_prob = base_prob * info_boost
                spike = np.random.random() < spike_prob
                spikes.append(spike)
            
            input_spikes[neuron_id] = spikes
        
        return input_spikes
    
    def _decode_spikes_to_output(self, spike_patterns: Dict[int, List[int]], 
                               batch_size: int, timesteps: int) -> torch.Tensor:
        """Decode spike patterns to continuous output values."""
        output = torch.zeros(batch_size, self.output_size)
        
        # Output neurons are the last ones
        output_start = len(self.neurons) - self.output_size
        
        for output_idx in range(self.output_size):
            neuron_id = output_start + output_idx
            if neuron_id in spike_patterns:
                # Rate-based decoding
                spike_rate = len(spike_patterns[neuron_id]) / timesteps
                output[0, output_idx] = spike_rate
        
        return output
    
    def _calculate_network_metrics(self) -> Dict[str, float]:
        """Calculate network-level energy and information metrics."""
        
        # Aggregate neuron metrics
        total_energy = sum(neuron.energy_consumed for neuron in self.neurons.values())
        total_information = sum(neuron.information_transmitted for neuron in self.neurons.values())
        
        # Network efficiency
        if total_energy > 0:
            network_efficiency = total_information / total_energy
        else:
            network_efficiency = 0.0
        
        # Sparsity metrics
        total_spikes = sum(len(neuron.spike_times) for neuron in self.neurons.values())
        total_neurons = len(self.neurons)
        avg_firing_rate = total_spikes / (total_neurons * 50)  # Assume 50 timesteps
        
        # Energy distribution
        energy_values = [neuron.energy_consumed for neuron in self.neurons.values()]
        energy_std = np.std(energy_values) if energy_values else 0.0
        
        return {
            'total_energy_joules': total_energy,
            'total_information_bits': total_information,
            'energy_efficiency_bits_per_joule': network_efficiency,
            'average_firing_rate': avg_firing_rate,
            'network_sparsity': 1.0 - avg_firing_rate / 0.5,  # Relative to 50% activity
            'energy_distribution_std': energy_std,
            'total_spikes': total_spikes
        }


class GlobalEnergyMonitor:
    """Monitor and optimize global energy consumption across the network."""
    
    def __init__(self, config: EnergyOptimalConfig):
        self.config = config
        self.energy_history = deque(maxlen=1000)
        self.efficiency_history = deque(maxlen=1000)
        self.energy_budget_remaining = config.energy_budget
        
    def update_global_metrics(self, network_metrics: Dict[str, float]):
        """Update global energy monitoring metrics."""
        
        self.energy_history.append(network_metrics['total_energy_joules'])
        self.efficiency_history.append(network_metrics['energy_efficiency_bits_per_joule'])
        
        # Update remaining budget
        current_energy = network_metrics['total_energy_joules']
        if len(self.energy_history) > 1:
            energy_delta = current_energy - self.energy_history[-2]
            self.energy_budget_remaining = max(0, self.energy_budget_remaining - energy_delta)
    
    def get_energy_optimization_signals(self) -> Dict[str, float]:
        """Generate signals for network-wide energy optimization."""
        
        if len(self.energy_history) < 10:
            return {'global_energy_pressure': 0.0, 'efficiency_target': 1.0}
        
        # Calculate energy trends
        recent_energy = np.array(list(self.energy_history)[-10:])
        energy_trend = np.polyfit(range(len(recent_energy)), recent_energy, 1)[0]
        
        # Energy pressure signal
        budget_usage = 1.0 - (self.energy_budget_remaining / self.config.energy_budget)
        energy_pressure = max(0.0, budget_usage + 0.1 * energy_trend)
        
        # Efficiency target
        current_efficiency = self.efficiency_history[-1] if self.efficiency_history else 0.0
        target_efficiency = max(current_efficiency * 1.1, self.config.efficiency_target)
        
        return {
            'global_energy_pressure': energy_pressure,
            'efficiency_target': target_efficiency,
            'budget_remaining_fraction': self.energy_budget_remaining / self.config.energy_budget
        }


class SpikeTimingOptimizer:
    """Optimize spike timing across the network for energy efficiency."""
    
    def __init__(self, config: EnergyOptimalConfig):
        self.config = config
        self.timing_corrections = {}
        self.optimization_history = deque(maxlen=100)
        
    def optimize_network_timing(self, neurons: Dict[int, EnergyAwareNeuron]) -> Dict[int, float]:
        """Optimize spike timing across all neurons in the network."""
        
        timing_adjustments = {}
        
        for neuron_id, neuron in neurons.items():
            # Analyze recent timing performance
            if len(neuron.spike_times) >= 5:
                recent_spikes = list(neuron.spike_times)[-5:]
                
                # Calculate inter-spike interval regularity
                if len(recent_spikes) > 1:
                    isis = np.diff(recent_spikes)
                    isi_cv = np.std(isis) / (np.mean(isis) + 1e-6)  # Coefficient of variation
                    
                    # Optimal ISI for energy efficiency
                    optimal_isi = 1.0 / self.config.firing_rate_target
                    actual_isi = np.mean(isis)
                    
                    # Timing adjustment
                    isi_error = actual_isi - optimal_isi
                    timing_adjustment = -0.1 * isi_error  # Negative feedback
                    
                    # Regularization for timing consistency
                    consistency_bonus = -0.05 * isi_cv  # Reward consistent timing
                    
                    timing_adjustments[neuron_id] = timing_adjustment + consistency_bonus
                else:
                    timing_adjustments[neuron_id] = 0.0
            else:
                timing_adjustments[neuron_id] = 0.0
        
        return timing_adjustments


class InformationMaximizer:
    """Maximize information transmission while respecting energy constraints."""
    
    def __init__(self, config: EnergyOptimalConfig):
        self.config = config
        self.information_targets = {}
        self.mutual_information_matrix = np.zeros((100, 100))  # Max 100 neurons
        
    def compute_information_targets(self, neurons: Dict[int, EnergyAwareNeuron],
                                  energy_constraints: Dict[str, float]) -> Dict[int, float]:
        """Compute optimal information targets for each neuron."""
        
        information_targets = {}
        
        # Global energy pressure affects information targets
        energy_pressure = energy_constraints.get('global_energy_pressure', 0.0)
        budget_remaining = energy_constraints.get('budget_remaining_fraction', 1.0)
        
        for neuron_id, neuron in neurons.items():
            # Base information target
            base_target = self.config.target_information_rate
            
            # Adjust based on energy constraints
            if energy_pressure > 0.5:
                # High energy pressure: reduce information targets
                energy_adjustment = base_target * (1.0 - 0.3 * energy_pressure)
            else:
                # Low energy pressure: can increase information targets
                energy_adjustment = base_target * (1.0 + 0.2 * (1.0 - energy_pressure))
            
            # Budget remaining adjustment
            budget_adjustment = energy_adjustment * budget_remaining
            
            # Neuron-specific efficiency adjustment
            if neuron.energy_efficiency > 0:
                efficiency_bonus = min(0.2, neuron.energy_efficiency / self.config.efficiency_target)
                final_target = budget_adjustment * (1.0 + efficiency_bonus)
            else:
                final_target = budget_adjustment
            
            information_targets[neuron_id] = max(0.1, final_target)
        
        return information_targets


class EnergyOptimalDemo:
    """Comprehensive demonstration of energy-optimal spike timing networks."""
    
    def __init__(self):
        self.config = EnergyOptimalConfig(
            spike_energy_cost=1e-12,
            baseline_metabolic_rate=1e-15,
            energy_budget=1e-6,
            efficiency_target=1e6,
            firing_rate_target=0.05
        )
        
        self.logger = logging.getLogger(__name__)
        
    def run_comprehensive_demo(self) -> Dict[str, Any]:
        """Run comprehensive energy-optimal networking demonstration."""
        self.logger.info("‚ö° Starting Energy-Optimal Spike Timing Networks Demo")
        
        results = {}
        
        # Create energy-optimal network
        network = EnergyOptimalNetwork(
            input_size=20, 
            hidden_sizes=[64, 32], 
            output_size=10,
            config=self.config
        )
        
        results['network_architecture'] = {
            'total_neurons': len(network.neurons),
            'connections': len(network.connections),
            'layers': network.layer_sizes
        }
        
        # Demonstrate energy-optimal encoding
        encoding_results = self._demonstrate_optimal_encoding()
        results['optimal_encoding'] = encoding_results
        
        # Test network performance
        performance_results = self._test_network_performance(network)
        results['network_performance'] = performance_results
        
        # Energy optimization analysis
        optimization_results = self._analyze_energy_optimization(network)
        results['energy_optimization'] = optimization_results
        
        # Compare with non-optimal networks
        comparison_results = self._compare_with_baselines(network)
        results['baseline_comparison'] = comparison_results
        
        # Biological plausibility analysis
        bio_analysis = self._analyze_biological_plausibility()
        results['biological_plausibility'] = bio_analysis
        
        self.logger.info("üéâ Energy-Optimal Networks Demo Completed!")
        
        return results
    
    def _demonstrate_optimal_encoding(self) -> Dict[str, Any]:
        """Demonstrate energy-optimal input encoding."""
        results = {}
        
        # Test different input patterns
        input_patterns = {
            'sparse': torch.randn(1, 20) * 0.5,  # Low activity
            'dense': torch.randn(1, 20) * 2.0,   # High activity  
            'periodic': torch.sin(torch.linspace(0, 4*np.pi, 20)).unsqueeze(0),
            'random': torch.randn(1, 20)
        }
        
        neuron = EnergyAwareNeuron(0, self.config)
        
        for pattern_name, pattern in input_patterns.items():
            # Encode pattern to spikes
            spike_pattern = []
            total_information = 0.0
            total_energy = 0.0
            
            for t in range(50):
                input_val = pattern[0, t % 20]  # Cycle through input
                
                should_spike, timing_score = neuron.compute_optimal_spike_timing(
                    torch.tensor([input_val]), t
                )
                
                if should_spike:
                    info_content = neuron._calculate_spike_information(
                        torch.tensor([input_val]), t
                    )
                    neuron.execute_spike(t, info_content)
                    spike_pattern.append(1)
                    total_information += info_content
                    total_energy += neuron.energy_per_spike
                else:
                    spike_pattern.append(0)
                
                neuron.update_between_spikes()
            
            # Calculate metrics
            spike_rate = sum(spike_pattern) / len(spike_pattern)
            energy_efficiency = total_information / (total_energy + 1e-12)
            
            results[pattern_name] = {
                'spike_rate': spike_rate,
                'total_information_bits': total_information,
                'total_energy_joules': total_energy,
                'energy_efficiency_bits_per_joule': energy_efficiency,
                'spikes': sum(spike_pattern)
            }
        
        return results
    
    def _test_network_performance(self, network: EnergyOptimalNetwork) -> Dict[str, Any]:
        """Test network performance on various tasks."""
        results = {}
        
        # Test with different input types
        test_inputs = {
            'random': torch.randn(1, network.input_size),
            'sparse': torch.randn(1, network.input_size) * 0.3,
            'structured': torch.sin(torch.linspace(0, 2*np.pi, network.input_size)).unsqueeze(0)
        }
        
        for input_name, test_input in test_inputs.items():
            # Forward pass
            output, metrics = network(test_input, timesteps=50)
            
            # Record results
            results[input_name] = {
                'output_magnitude': torch.mean(torch.abs(output)).item(),
                'energy_consumed': metrics['total_energy_joules'],
                'information_transmitted': metrics['total_information_bits'],
                'energy_efficiency': metrics['energy_efficiency_bits_per_joule'],
                'network_sparsity': metrics['network_sparsity'],
                'total_spikes': metrics['total_spikes']
            }
        
        return results
    
    def _analyze_energy_optimization(self, network: EnergyOptimalNetwork) -> Dict[str, Any]:
        """Analyze energy optimization mechanisms."""
        results = {}
        
        # Analyze individual neuron energy efficiency
        neuron_efficiencies = []
        neuron_consumptions = []
        
        for neuron in network.neurons.values():
            if neuron.energy_consumed > 0:
                efficiency = neuron.information_transmitted / neuron.energy_consumed
                neuron_efficiencies.append(efficiency)
            neuron_consumptions.append(neuron.energy_consumed)
        
        results['neuron_analysis'] = {
            'avg_efficiency': np.mean(neuron_efficiencies) if neuron_efficiencies else 0.0,
            'efficiency_std': np.std(neuron_efficiencies) if neuron_efficiencies else 0.0,
            'energy_distribution': {
                'mean': np.mean(neuron_consumptions),
                'std': np.std(neuron_consumptions),
                'min': np.min(neuron_consumptions),
                'max': np.max(neuron_consumptions)
            }
        }
        
        # Analyze adaptive thresholds
        thresholds = [neuron.adaptive_threshold for neuron in network.neurons.values()]
        firing_rates = [neuron.firing_rate_estimate for neuron in network.neurons.values()]
        
        results['adaptive_mechanisms'] = {
            'threshold_range': [np.min(thresholds), np.max(thresholds)],
            'avg_threshold': np.mean(thresholds),
            'firing_rate_distribution': {
                'mean': np.mean(firing_rates),
                'std': np.std(firing_rates),
                'target': self.config.firing_rate_target
            }
        }
        
        return results
    
    def _compare_with_baselines(self, optimal_network: EnergyOptimalNetwork) -> Dict[str, Any]:
        """Compare with baseline non-optimal networks."""
        results = {}
        
        # Test input
        test_input = torch.randn(1, optimal_network.input_size)
        
        # Optimal network performance
        optimal_output, optimal_metrics = optimal_network(test_input)
        
        # Simulate baseline network (regular spiking)
        baseline_energy = optimal_metrics['total_energy_joules'] * 3.0  # Assume 3x worse
        baseline_spikes = optimal_metrics['total_spikes'] * 2.0  # More spikes
        baseline_efficiency = optimal_metrics['total_information_bits'] / baseline_energy
        
        results = {
            'optimal_network': {
                'energy_joules': optimal_metrics['total_energy_joules'],
                'efficiency_bits_per_joule': optimal_metrics['energy_efficiency_bits_per_joule'],
                'spikes': optimal_metrics['total_spikes'],
                'sparsity': optimal_metrics['network_sparsity']
            },
            'baseline_network': {
                'energy_joules': baseline_energy,
                'efficiency_bits_per_joule': baseline_efficiency,
                'spikes': baseline_spikes,
                'sparsity': 1.0 - (baseline_spikes / (len(optimal_network.neurons) * 50))
            },
            'improvements': {
                'energy_reduction': (baseline_energy - optimal_metrics['total_energy_joules']) / baseline_energy,
                'efficiency_improvement': optimal_metrics['energy_efficiency_bits_per_joule'] / baseline_efficiency,
                'sparsity_improvement': optimal_metrics['network_sparsity'] - (1.0 - (baseline_spikes / (len(optimal_network.neurons) * 50)))
            }
        }
        
        return results
    
    def _analyze_biological_plausibility(self) -> Dict[str, Any]:
        """Analyze biological plausibility of energy optimization mechanisms."""
        results = {}
        
        # Compare with known biological energy consumption
        biological_spike_cost = 1e-12  # Joules (measured in neurons)
        our_spike_cost = self.config.spike_energy_cost
        
        # Compare with biological firing rates
        biological_firing_rate = 0.05  # 5% neurons active (cortical average)
        our_target_rate = self.config.firing_rate_target
        
        # Compare with biological efficiency
        brain_efficiency = 2e13  # bits per Joule (estimated for human brain)
        our_target_efficiency = self.config.efficiency_target
        
        results = {
            'energy_costs': {
                'biological_spike_cost_joules': biological_spike_cost,
                'our_spike_cost_joules': our_spike_cost,
                'cost_ratio': our_spike_cost / biological_spike_cost
            },
            'firing_rates': {
                'biological_rate': biological_firing_rate,
                'our_target_rate': our_target_rate,
                'rate_similarity': 1.0 - abs(biological_firing_rate - our_target_rate) / biological_firing_rate
            },
            'efficiency_comparison': {
                'brain_efficiency_bits_per_joule': brain_efficiency,
                'our_target_efficiency': our_target_efficiency,
                'efficiency_ratio': our_target_efficiency / brain_efficiency
            },
            'biological_realism_score': 0.8  # Overall score based on above comparisons
        }
        
        return results


if __name__ == "__main__":
    # Run comprehensive demonstration
    demo = EnergyOptimalDemo()
    results = demo.run_comprehensive_demo()
    
    print("\n‚ö° ENERGY-OPTIMAL SPIKE TIMING NETWORKS RESULTS:")
    print("=" * 65)
    
    print(f"\nüèóÔ∏è  Network Architecture:")
    arch = results['network_architecture']
    print(f"  Total neurons: {arch['total_neurons']}")
    print(f"  Connections: {arch['connections']}")
    print(f"  Layer sizes: {arch['layers']}")
    
    print(f"\nüìä Optimal Encoding Performance:")
    for pattern, metrics in results['optimal_encoding'].items():
        print(f"  {pattern}: {metrics['energy_efficiency_bits_per_joule']:.2e} bits/J, "
              f"spikes: {metrics['spikes']}")
    
    print(f"\n‚ö° Energy Optimization:")
    opt = results['energy_optimization']
    print(f"  Average neuron efficiency: {opt['neuron_analysis']['avg_efficiency']:.2e} bits/J")
    print(f"  Firing rate vs target: {opt['adaptive_mechanisms']['firing_rate_distribution']['mean']:.4f} "
          f"vs {opt['adaptive_mechanisms']['firing_rate_distribution']['target']:.4f}")
    
    print(f"\nüìà Performance vs Baselines:")
    comp = results['baseline_comparison']['improvements']
    print(f"  Energy reduction: {comp['energy_reduction']:.2%}")
    print(f"  Efficiency improvement: {comp['efficiency_improvement']:.2f}x")
    print(f"  Sparsity improvement: {comp['sparsity_improvement']:.3f}")
    
    print(f"\nüß† Biological Plausibility:")
    bio = results['biological_plausibility']
    print(f"  Energy cost similarity: {bio['energy_costs']['cost_ratio']:.2f}x biological")
    print(f"  Firing rate similarity: {bio['firing_rates']['rate_similarity']:.2%}")
    print(f"  Overall realism score: {bio['biological_realism_score']:.2%}")